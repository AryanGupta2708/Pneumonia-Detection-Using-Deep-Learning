{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pneumonia Prediction using Convulational Neural Network\n",
    "\n",
    "The images trained, tested and validated for the neural network are chest X-Ray images. The implementation of clinical-decision support algorithms for medical imaging faces challenges with reliability and interpretability. Here, I establish a diagnostic tool based on a deep-learning framework for the screening of patients with common treatable blinding retinal diseases.\n",
    "\n",
    "![](http://miro.medium.com/max/1838/1*t-_EXQ3tlb8KOx6H7HN09A.jpeg)\n",
    "\n",
    "* The **normal** chest X-ray depicts clear lungs without any areas of abnormal opacification in the image. \n",
    "* **Bacterial pneumonia** typically exhibits a focal lobar consolidation around upper lobes (white arrows)\n",
    "* **Viral pneumonia** manifests with a more diffuse ‘‘interstitial’’ pattern in both lungs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gradio\n",
      "  Obtaining dependency information for gradio from https://files.pythonhosted.org/packages/df/e7/e0b548208ff5db6323ad974f094e9435adb0a377f35274196fb74adaf58a/gradio-3.41.2-py3-none-any.whl.metadata\n",
      "  Using cached gradio-3.41.2-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in d:\\software\\anaconda\\lib\\site-packages (from gradio) (22.1.0)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio)\n",
      "  Obtaining dependency information for altair<6.0,>=4.2.0 from https://files.pythonhosted.org/packages/2b/40/ff33821bca16cac30f8d9c3244ac961416f40bf2d3261a1250aabda33a6f/altair-5.1.0-py3-none-any.whl.metadata\n",
      "  Using cached altair-5.1.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting fastapi (from gradio)\n",
      "  Obtaining dependency information for fastapi from https://files.pythonhosted.org/packages/89/e1/5391318b8b35eb4873ea504ca5181a5569d8e499a0920a61ba7e29e8fc2a/fastapi-0.103.0-py3-none-any.whl.metadata\n",
      "  Using cached fastapi-0.103.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Using cached ffmpy-0.3.1-py3-none-any.whl\n",
      "Collecting gradio-client==0.5.0 (from gradio)\n",
      "  Obtaining dependency information for gradio-client==0.5.0 from https://files.pythonhosted.org/packages/fe/85/ec0323f39192c4bee04e8e06e64213aff816b9d1b61c3c8367e75b1c7e10/gradio_client-0.5.0-py3-none-any.whl.metadata\n",
      "  Using cached gradio_client-0.5.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx (from gradio)\n",
      "  Obtaining dependency information for httpx from https://files.pythonhosted.org/packages/ec/91/e41f64f03d2a13aee7e8c819d82ee3aa7cdc484d18c0ae859742597d5aa0/httpx-0.24.1-py3-none-any.whl.metadata\n",
      "  Using cached httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting huggingface-hub>=0.14.0 (from gradio)\n",
      "  Obtaining dependency information for huggingface-hub>=0.14.0 from https://files.pythonhosted.org/packages/7f/c4/adcbe9a696c135578cabcbdd7331332daad4d49b7c43688bc2d36b3a47d2/huggingface_hub-0.16.4-py3-none-any.whl.metadata\n",
      "  Using cached huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio)\n",
      "  Obtaining dependency information for importlib-resources<7.0,>=1.3 from https://files.pythonhosted.org/packages/25/d4/592f53ce2f8dde8be5720851bd0ab71cc2e76c55978e4163ef1ab7e389bb/importlib_resources-6.0.1-py3-none-any.whl.metadata\n",
      "  Using cached importlib_resources-6.0.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in d:\\software\\anaconda\\lib\\site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in d:\\software\\anaconda\\lib\\site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: matplotlib~=3.0 in d:\\software\\anaconda\\lib\\site-packages (from gradio) (3.7.1)\n",
      "Requirement already satisfied: numpy~=1.0 in d:\\software\\anaconda\\lib\\site-packages (from gradio) (1.24.3)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Obtaining dependency information for orjson~=3.0 from https://files.pythonhosted.org/packages/e1/f1/6a2e00b9663d493612374d40f28605cccc68e77d7eeb89459b3f2b00e8c7/orjson-3.9.5-cp311-none-win_amd64.whl.metadata\n",
      "  Using cached orjson-3.9.5-cp311-none-win_amd64.whl.metadata (50 kB)\n",
      "Requirement already satisfied: packaging in d:\\software\\anaconda\\lib\\site-packages (from gradio) (23.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in d:\\software\\anaconda\\lib\\site-packages (from gradio) (1.5.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in d:\\software\\anaconda\\lib\\site-packages (from gradio) (9.4.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 (from gradio)\n",
      "  Obtaining dependency information for pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 from https://files.pythonhosted.org/packages/82/06/fafdc75e48b248eff364b4249af4bcc6952225e8f20e8205820afc66e88e/pydantic-2.3.0-py3-none-any.whl.metadata\n",
      "  Using cached pydantic-2.3.0-py3-none-any.whl.metadata (148 kB)\n",
      "Collecting pydub (from gradio)\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting python-multipart (from gradio)\n",
      "  Using cached python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in d:\\software\\anaconda\\lib\\site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: requests~=2.0 in d:\\software\\anaconda\\lib\\site-packages (from gradio) (2.31.0)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in d:\\software\\anaconda\\lib\\site-packages (from gradio) (4.7.1)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Obtaining dependency information for uvicorn>=0.14.0 from https://files.pythonhosted.org/packages/79/96/b0882a1c3f7ef3dd86879e041212ae5b62b4bd352320889231cc735a8e8f/uvicorn-0.23.2-py3-none-any.whl.metadata\n",
      "  Using cached uvicorn-0.23.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio)\n",
      "  Using cached websockets-11.0.3-cp311-cp311-win_amd64.whl (124 kB)\n",
      "Requirement already satisfied: fsspec in d:\\software\\anaconda\\lib\\site-packages (from gradio-client==0.5.0->gradio) (2023.3.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in d:\\software\\anaconda\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: toolz in d:\\software\\anaconda\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: filelock in d:\\software\\anaconda\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (3.9.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\software\\anaconda\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (4.65.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\software\\anaconda\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\software\\anaconda\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\software\\anaconda\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\software\\anaconda\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\software\\anaconda\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\software\\anaconda\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\software\\anaconda\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2022.7)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio)\n",
      "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/d8/f0/a2ee543a96cc624c35a9086f39b1ed2aa403c6d355dfe47a11ee5c64a164/annotated_types-0.5.0-py3-none-any.whl.metadata\n",
      "  Using cached annotated_types-0.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pydantic-core==2.6.3 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio)\n",
      "  Obtaining dependency information for pydantic-core==2.6.3 from https://files.pythonhosted.org/packages/29/37/eb1c5853ecaac79d2dc19be206fd6732fdfa6a6bf705048d0a1046c5fa8d/pydantic_core-2.6.3-cp311-none-win_amd64.whl.metadata\n",
      "  Using cached pydantic_core-2.6.3-cp311-none-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\software\\anaconda\\lib\\site-packages (from requests~=2.0->gradio) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\software\\anaconda\\lib\\site-packages (from requests~=2.0->gradio) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\software\\anaconda\\lib\\site-packages (from requests~=2.0->gradio) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\software\\anaconda\\lib\\site-packages (from requests~=2.0->gradio) (2023.7.22)\n",
      "Requirement already satisfied: click>=7.0 in d:\\software\\anaconda\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (8.0.4)\n",
      "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
      "  Obtaining dependency information for starlette<0.28.0,>=0.27.0 from https://files.pythonhosted.org/packages/58/f8/e2cca22387965584a409795913b774235752be4176d276714e15e1a58884/starlette-0.27.0-py3-none-any.whl.metadata\n",
      "  Using cached starlette-0.27.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio)\n",
      "  Obtaining dependency information for httpcore<0.18.0,>=0.15.0 from https://files.pythonhosted.org/packages/94/2c/2bde7ff8dd2064395555220cbf7cba79991172bf5315a07eb3ac7688d9f1/httpcore-0.17.3-py3-none-any.whl.metadata\n",
      "  Using cached httpcore-0.17.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: sniffio in d:\\software\\anaconda\\lib\\site-packages (from httpx->gradio) (1.2.0)\n",
      "Requirement already satisfied: colorama in d:\\software\\anaconda\\lib\\site-packages (from click>=7.0->uvicorn>=0.14.0->gradio) (0.4.6)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in d:\\software\\anaconda\\lib\\site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.5.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in d:\\software\\anaconda\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in d:\\software\\anaconda\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\software\\anaconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Using cached gradio-3.41.2-py3-none-any.whl (20.1 MB)\n",
      "Using cached gradio_client-0.5.0-py3-none-any.whl (298 kB)\n",
      "Using cached altair-5.1.0-py3-none-any.whl (520 kB)\n",
      "Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "Using cached importlib_resources-6.0.1-py3-none-any.whl (34 kB)\n",
      "Using cached orjson-3.9.5-cp311-none-win_amd64.whl (139 kB)\n",
      "Using cached pydantic-2.3.0-py3-none-any.whl (374 kB)\n",
      "Using cached pydantic_core-2.6.3-cp311-none-win_amd64.whl (1.7 MB)\n",
      "Using cached uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
      "Using cached fastapi-0.103.0-py3-none-any.whl (66 kB)\n",
      "Using cached httpx-0.24.1-py3-none-any.whl (75 kB)\n",
      "Using cached annotated_types-0.5.0-py3-none-any.whl (11 kB)\n",
      "Using cached httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
      "Using cached starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "Installing collected packages: pydub, ffmpy, websockets, semantic-version, python-multipart, pydantic-core, orjson, importlib-resources, h11, annotated-types, uvicorn, starlette, pydantic, huggingface-hub, httpcore, httpx, fastapi, altair, gradio-client, gradio\n",
      "Successfully installed altair-5.1.0 annotated-types-0.5.0 fastapi-0.103.0 ffmpy-0.3.1 gradio-3.41.2 gradio-client-0.5.0 h11-0.14.0 httpcore-0.17.3 httpx-0.24.1 huggingface-hub-0.16.4 importlib-resources-6.0.1 orjson-3.9.5 pydantic-2.3.0 pydantic-core-2.6.3 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.27.0 uvicorn-0.23.2 websockets-11.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script uvicorn.exe is installed in 'C:\\Users\\aryan\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script huggingface-cli.exe is installed in 'C:\\Users\\aryan\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script httpx.exe is installed in 'C:\\Users\\aryan\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts gradio.exe and upload_theme.exe are installed in 'C:\\Users\\aryan\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in d:\\software\\anaconda\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in d:\\software\\anaconda\\lib\\site-packages (from seaborn) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.25 in d:\\software\\anaconda\\lib\\site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in d:\\software\\anaconda\\lib\\site-packages (from seaborn) (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\software\\anaconda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\software\\anaconda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\software\\anaconda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\software\\anaconda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\software\\anaconda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\software\\anaconda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\software\\anaconda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\software\\anaconda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\software\\anaconda\\lib\\site-packages (from pandas>=0.25->seaborn) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in d:\\software\\anaconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting keras\n",
      "  Obtaining dependency information for keras from https://files.pythonhosted.org/packages/2e/f3/19da7511b45e80216cbbd9467137b2d28919c58ba1ccb971435cb631e470/keras-2.13.1-py3-none-any.whl.metadata\n",
      "  Using cached keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.13.1\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in d:\\software\\anaconda\\lib\\site-packages (1.24.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in d:\\software\\anaconda\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\software\\anaconda\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\software\\anaconda\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in d:\\software\\anaconda\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\software\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in d:\\software\\anaconda\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\software\\anaconda\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in d:\\software\\anaconda\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\software\\anaconda\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\software\\anaconda\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio\n",
    "!pip install seaborn\n",
    "!pip install keras\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import Input, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "**Getting training, validation and testing data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['PNEUMONIA', 'NORMAL']\n",
    "img_size = 150\n",
    "def get_data(data_dir):\n",
    "    data = [] \n",
    "    for label in labels: \n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_data('../input/chest-xray-pneumonia/chest_xray/train')\n",
    "test = get_data('../input/chest-xray-pneumonia/chest_xray/test')\n",
    "val = get_data('../input/chest-xray-pneumonia/chest_xray/val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting x and y labels of training, validation and testing dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for feature, label in train:\n",
    "    x_train.append(feature)\n",
    "    y_train.append(label)\n",
    "\n",
    "for feature, label in test:\n",
    "    x_test.append(feature)\n",
    "    y_test.append(label)\n",
    "    \n",
    "for feature, label in val:\n",
    "    x_val.append(feature)\n",
    "    y_val.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives=[]\n",
    "negatives=[]\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i]:\n",
    "        positives.append(x_train[i])\n",
    "    else:\n",
    "        negatives.append(x_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(labels, [len(negatives), len(positives)], color=[\"green\", \"blue\"])\n",
    "plt.title(\"Cases count in training data set\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(positives[0])\n",
    "plt.title(\"Pneumonia\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(negatives[4], cmap=\"gray\")\n",
    "plt.title(\"Normal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performing a grayscale normalization to reduce the effect of illumination's differences.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "x_train = np.array(x_train) / 255\n",
    "x_val = np.array(x_val) / 255\n",
    "x_test = np.array(x_test) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resizing the data for CNN training and testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize data for deep learning \n",
    "x_train = x_train.reshape(-1, img_size, img_size, 1)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_val = x_val.reshape(-1, img_size, img_size, 1)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "x_test = x_test.reshape(-1, img_size, img_size, 1)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_val = y_val.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "In order to avoid overfitting problem, we can expand artificially our dataset. This can be done by altering the training data with small transformations to reproduce the variations. \n",
    "\n",
    "Some popular augmentations people use are grayscales, horizontal flips, vertical flips, random crops, color jitters, translations, rotations, and much more. By applying just a couple of these transformations to our training data, we can easily double or triple the number of training examples and create a very robust model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip = True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (150,150,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "\n",
    "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "\n",
    "model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 128 , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 1 , activation = 'sigmoid'))\n",
    "model.compile(optimizer = \"rmsprop\" , loss = 'binary_crossentropy' , metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"rmsprop\" , \n",
    "            loss = 'binary_crossentropy' , \n",
    "            metrics = ['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience = 2, \n",
    "                                            verbose=1,\n",
    "                                            factor=0.3, \n",
    "                                            min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(datagen.flow(x_train,y_train, batch_size = 32) ,\n",
    "                    epochs = 10 , \n",
    "                    validation_data = datagen.flow(x_val, y_val) ,\n",
    "                    callbacks = learning_rate_reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('kaggle/saved_model_ai/pneumoniadetection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss of the model is - \" , model.evaluate(x_test,y_test)[0])\n",
    "print(\"Accuracy of the model is - \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(range(10))\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "fig.set_size_inches(20,10)\n",
    "\n",
    "ax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\n",
    "ax[0].plot(epochs , val_acc , 'ro-' , label = 'Validation Accuracy')\n",
    "ax[0].set_title('Training & Validation Accuracy')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(\"Accuracy\")\n",
    "\n",
    "ax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\n",
    "ax[1].plot(epochs , val_loss , 'r-o' , label = 'Validation Loss')\n",
    "ax[1].set_title('Testing Accuracy & Loss')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_ylabel(\"Training & Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test) \n",
    "for i in range(len(predictions)): \n",
    "    predictions[i] = 1 if predictions[i]>0.5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, \n",
    "                            predictions, \n",
    "                            target_names = ['Pneumonia (Class 0)','Normal (Class 1)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "![](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,predictions)\n",
    "cm = pd.DataFrame(cm , index = ['0','1'] , columns = ['0','1'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, cmap=\"Blues\", annot=True, xticklabels = labels,yticklabels = labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pneumoniaPrediction(img):\n",
    "    img = np.array(img)/255\n",
    "    img = img.reshape(-1, 150, 150, 1)\n",
    "    isPneumonic = model.predict(img)[0]\n",
    "    imgClass = \"Normal\" if isPneumonic<0.5 else \"Pneumonic\"\n",
    "    return imgClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = model.predict(x_test)\n",
    "for i in range(len(pr)):\n",
    "    if pr[i]>0.5:\n",
    "        pr[i]=1\n",
    "    else:\n",
    "        pr[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gradio.inputs.Image(shape=(150, 150))\n",
    "label = gradio.outputs.Label(num_top_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = gradio.Interface(fn = pneumoniaPrediction,\n",
    "                            title = \"Pneumonia Detection using Chest X-Ray\",\n",
    "                            inputs = img,\n",
    "                            outputs = label,\n",
    "                            interpretation = \"default\")\n",
    "interface.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
